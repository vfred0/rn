{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "355facec",
   "metadata": {
    "id": "355facec"
   },
   "source": [
    "# Definición de modelo GAN para generación de imágenes\n",
    "La siguiente celda de código define una red GAN, que tiene dos subredes, una para generar imágenes y otra para discriminar (identificar) si las imágenes generadas son distintas a las reales. Ambas redes se entrenan al mismo tiempo, de forma tal que a medida que la primera aprende a generar imágenes cada vez más reales, la segunda aprende a identificar si lo son realmente.\n",
    "\n",
    "\n",
    "No es el objetivo entender todo el código, simplemente correr la celda para definir la red y luego entrenarla y usarla más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23852339",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3158,
     "status": "ok",
     "timestamp": 1621548373690,
     "user": {
      "displayName": "Redes Neuronales",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gige9Oo1hxhNPn72H65kzsRa5nIZBRHoGsUbiva=s64",
      "userId": "11347185938143135425"
     },
     "user_tz": 180
    },
    "id": "23852339",
    "outputId": "5d5963e8-1794-4273-effc-146b4fc2c635"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 2\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "        print(\"Detalles del modelo generador:\")\n",
    "        model.summary()\n",
    "        print(\"\\n\")\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        \n",
    "        print(\"Detalles del modelo discriminador:\")\n",
    "        model.summary()\n",
    "        print(\"\\n\")\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Train the generator (to have the discriminator label samples as valid)\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            \n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                print (\"Iteración %d → [Error D: %f, acc.: %.2f%%] [Error G: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "                print(\"Ejemplo de imágenes generadas:\")\n",
    "                self.sample_images(epoch)\n",
    "                \n",
    "\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        plt.show()\n",
    "\n",
    "# fijar la semilla\n",
    "# no es necesario en la práctica, \n",
    "# lo hacemos para poder replicar los experimentos\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "# definir la red\n",
    "gan = GAN()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64f0a18",
   "metadata": {
    "id": "b64f0a18"
   },
   "source": [
    "# Entrenamiento\n",
    "\n",
    "El modelo se entrena con el conjunto de datos MNIST para aprender a generar imágenes de dígitos manuscritos. A medida que avanza el proceso las imágenes suelen ir mejorando. \n",
    "\n",
    "Probá modificar la cantidad de épocas o entrenarlo varias veces (equivalente) para ver como cambian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3933b",
   "metadata": {
    "id": "53e3933b"
   },
   "outputs": [],
   "source": [
    "# Entrenar la red (tarda aprox. 10-15 minutos)\n",
    "gan.train(epochs=2000, batch_size=32, sample_interval=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79c7a81",
   "metadata": {
    "id": "c79c7a81"
   },
   "source": [
    "# Generación de imágenes con el modelo entrenado\n",
    "En base a los valores de entrada num1 y num2, se genera la imagen. Probá modificarlos y ver si podés encontrar ciertos rangos de valores que generan cada dígito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af238a1",
   "metadata": {
    "id": "1af238a1"
   },
   "outputs": [],
   "source": [
    "# Elegir dos números al azar, entre -1 y 1 preferentemente\n",
    "num1=0.5\n",
    "num2=0.1\n",
    "# Generar un vector latente que codifica la imagen a generar con solo estos dos números\n",
    "entrada = np.array([[num1,num2]])\n",
    "# Generar la imagen\n",
    "imagen_generada = gan.generator.predict(entrada)\n",
    "# mostrarla\n",
    "plt.figure(figsize = (1,1))\n",
    "plt.imshow(imagen_generada[0,:,:,0],cmap=\"gray\",)\n",
    "# Ejecuta varias veces esta celda para ver como cambia la imagen generada"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Generación de imágenes con Generative Adversarial Networks (GAN).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
