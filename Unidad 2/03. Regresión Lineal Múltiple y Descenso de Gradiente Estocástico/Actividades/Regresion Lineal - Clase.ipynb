{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "KcqFqabpYYNZ"
   },
   "source": [
    "# Regresión Lineal  con Múltiples Variables de Entrada \n",
    "\n",
    "\n",
    "En este ejercicio, tu objetivo será implementar el método `forward` de un modelo de Regresión Lineal con una múltiples variables de entrada y _una_ de salida. No debés implementar ningún otro método.\n",
    "\n",
    "La función se encuentra en la clase `RegresionLineal`.\n",
    "\n",
    "Luego, ejecuta las pruebas para verificar que implementaste correctamente el modelo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7582,
     "status": "ok",
     "timestamp": 1648499849613,
     "user": {
      "displayName": "Redes Neuronales",
      "userId": "11347185938143135425"
     },
     "user_tz": 180
    },
    "id": "-IOJzhM8YYNb",
    "outputId": "c8c57471-c943-4192-d09c-41d8c1e41029"
   },
   "outputs": [],
   "source": [
    "!pip install -q rnutil\n",
    "import rnutil\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RegresionLineal:\n",
    "    '''\n",
    "    Esta clase permite entrenar modelos de regresión lineal, cuya función de predicción es:\n",
    "    y = x . w + b\n",
    "    Los parámetros son:\n",
    "    w: un vector de flotantes de la misma dimensionalidad de x, es decir un vector de tamaño dx1\n",
    "    b (un flotante)\n",
    "    La entrada x debe ser d dimensional, es decir, un vector de tamanio 1xd (o n de tamanño nxd).\n",
    "    '''\n",
    "\n",
    "    def __init__(self,w:np.ndarray,b:float):\n",
    "        self.w=w\n",
    "        self.b=b\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(w = {self.w}, b = {self.b:.5f})\"\n",
    "\n",
    "    def forward(self,x:np.ndarray):\n",
    "        '''\n",
    "        Debés implementar el forward del modelo\n",
    "        :param x: vector de d dimensiones y n ejemplos con los valores de entrada\n",
    "        :return: la predicción x*w+b\n",
    "        '''\n",
    "        n,d=x.shape\n",
    "        \n",
    "        assert (len(self.w) == d)\n",
    "        \n",
    "        y=np.zeros(n)\n",
    "\n",
    "        ### IMPLEMENTAR ####\n",
    "        # Calcular la salida *y* en base a: \n",
    "        # x: valor de entrada\n",
    "        # self.w: vector de pesos (variable de instancia, por eso el \"self.\")\n",
    "        # self.b: sesgo o bias (variable de instancia, por eso el \"self.\")\n",
    "        # Ejemplo\n",
    "        # x = NxD = 5x3\n",
    "        # w = 3x1\n",
    "        # np.dot(a,b) : producto escalar\n",
    "        # a @ b : mult de matrices\n",
    "        # y = x * w + b\n",
    "        # for i in range(n):\n",
    "        #   xi = x[i,:]\n",
    "        #   # xi : 1x3\n",
    "        #   y[i] = \n",
    "\n",
    "        \n",
    "        assert (len(y) == n)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    def backward(self,x:np.ndarray,y:np.ndarray)->(float,float):\n",
    "        '''\n",
    "        Calcula las derivadas de los parámetros del modelo con respecto \n",
    "        al error cuadrático medio y al conjunto de datos (x,y)\n",
    "        No necesitas implementar nada aqui\n",
    "        :param x: vector de d dimensiones y n ejemplos con los valores de entrada\n",
    "        :param y: vector 1D con los n valores de salida _verdaderos_ \n",
    "        :return derivada del error respecto de w y b\n",
    "        '''\n",
    "        d=len(self.w)\n",
    "        yhat = self.forward(x)\n",
    "        # calculo de derivadas\n",
    "        dEdw=np.zeros(d)\n",
    "        for i in range(d):\n",
    "            dEdw[i] = 2 * ((yhat - y)*x[:,i]).mean()\n",
    "        dEdb = 2 * (yhat - y).mean()\n",
    "        return dEdw,dEdb\n",
    "\n",
    "    def fit(self,x:np.ndarray,y:np.ndarray,lr:float=0.001,epochs:int=100):\n",
    "        '''\n",
    "        No necesitas implementar nada aqui\n",
    "        Entrena el modelo (ajusta los parámetros) para minimizar el error cuadrático medio\n",
    "        Mediante descenso de gradiente\n",
    "        :param x: vector de d dimensiones y n ejemplos con los valores de entrada\n",
    "        :param y: vector 1D con los n valores de salida _verdaderos_ \n",
    "        :param alpha: velocidad de aprendizaje\n",
    "        :param iterations: cantidad de iteraciones de aprendizaje\n",
    "        '''\n",
    "        \n",
    "        assert (len(x.shape) == 2)\n",
    "        assert (len(y.shape) == 1)\n",
    "        assert ( len(y) == len(x))\n",
    "        n = len(x)\n",
    "\n",
    "        for i in range(epochs):\n",
    "            dEdw,dEdb=self.backward(x,y)\n",
    "            # actualizo los parámetros\n",
    "            self.w = self.w - lr * dEdw # dEdw es un vector con tantos valores como w\n",
    "            self.b = self.b - lr * dEdb\n",
    "            print(f\"Epoch {i+1}/{epochs} => Error = {self.error(x,y)}\")\n",
    "        \n",
    "    def error(self,x:np.ndarray,y:np.ndarray)->float:\n",
    "        '''\n",
    "        Error cuadrático medio (MSE) del modelo\n",
    "        No necesitas implementar nada aqui\n",
    "        :param x: vector de d dimensiones y n ejemplos con los valores de entrada\n",
    "        :param y: vector 1D con los n valores de salida _verdaderos_ \n",
    "        :return flotante con el error promedio del modelo entre todos los ejemplos\n",
    "        '''\n",
    "        \n",
    "        yhat = self.forward(x)\n",
    "        d2 = (y-yhat)**2\n",
    "        return d2.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlZ9G5NRYYNl"
   },
   "source": [
    "# Ejecuta el siguiente bloque para verificar que la función `forward` está bien implementada. \n",
    "\n",
    "Si todos los valores son iguales, la implementación del `forward` debería estar bien realizada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1648499849614,
     "user": {
      "displayName": "Redes Neuronales",
      "userId": "11347185938143135425"
     },
     "user_tz": 180
    },
    "id": "lmm9oQ4VYYNm",
    "outputId": "b835a602-fd45-4a1c-8bc5-8827caac17d5"
   },
   "outputs": [],
   "source": [
    "x=np.array([[1.0,2.0]\n",
    "            ,[2.0,3.0]\n",
    "            ,[3.0,4.0]])\n",
    "\n",
    "w1=np.zeros(2) # [0,0]\n",
    "rl1=RegresionLineal(w1,0.0)\n",
    "y=rl1.forward(x)\n",
    "rnutil.verificar_igualdad(y,np.zeros(3))\n",
    "\n",
    "\n",
    "w2=np.ones(2)\n",
    "rl2=RegresionLineal(w2,0.0)\n",
    "y=rl2.forward(x)\n",
    "rnutil.verificar_igualdad(y,np.array([3.0,5.0,7.0]))\n",
    "\n",
    "w3=np.zeros(2)\n",
    "rl3=RegresionLineal(w3,1.0)\n",
    "y=rl3.forward(x)\n",
    "rnutil.verificar_igualdad(y,np.ones(3))\n",
    "\n",
    "\n",
    "w4=np.ones(2)\n",
    "rl4=RegresionLineal(w4,1.0)\n",
    "y=rl4.forward(x)\n",
    "rnutil.verificar_igualdad(y,np.array([4.0,6.0,8.0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lh12c0Q9YYNu"
   },
   "source": [
    "# Verifica que el modelo se entrena correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3938,
     "status": "ok",
     "timestamp": 1648499853547,
     "user": {
      "displayName": "Redes Neuronales",
      "userId": "11347185938143135425"
     },
     "user_tz": 180
    },
    "id": "GD4l4mZxYYNv",
    "outputId": "febf2a48-9e5a-4fa5-b5db-f0e52839f0c8"
   },
   "outputs": [],
   "source": [
    "# Carga del dataset\n",
    "data=rnutil.load_dataset_numpy(\"study_regression_2d_small.csv\")\n",
    "#dividir en entradas y salidas\n",
    "x,y=data[:,0:2],data[:,2]\n",
    "# tamaño de los datos\n",
    "# n= cant de ejemplos\n",
    "# cant de dimensiones\n",
    "n,d=x.shape\n",
    "\n",
    "print(\"Si no implementaste el forward, el entrenamiento no funcionará correctamente.\")\n",
    "# Creación del modelo inicial\n",
    "print(\"Inicialización aleatoria del modelo; vuelve a correr esta celda para obtener otros resultados\")\n",
    "w_random=np.random.rand(d)\n",
    "b_random=np.random.rand()\n",
    "rl=RegresionLineal(w_random,b_random)\n",
    "\n",
    "# visualización del modelo inicial\n",
    "print(f\"Modelo inicial: {rl}. Error cuadrático medio: {rl.error(x,y):.4f}\")\n",
    "rnutil.plot_regresion_lineal(rl.w,rl.b,x[:,0],x[:,1],y,\"x1 (Horas estudiadas)\",\"x2 (Promedio)\",\"y (Nota)\",title=\"Modelo Inicial\")\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "rl.fit(x,y,lr=0.001,epochs=100)\n",
    "\n",
    "# visualiza el modelo y los datos\n",
    "rnutil.plot_regresion_lineal(rl.w,rl.b,x[:,0],x[:,1],y,\"x1 (Horas estudiadas)\",\"x2 (Promedio)\",\"y (Nota)\",title=\"Modelo Final\")\n",
    "print(f\"Modelo inicial: {rl}. Error cuadrático medio: {rl.error(x,y):.4f}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regresion Lineal - Clase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
