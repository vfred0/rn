{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fp0BCyTO-ojk"
   },
   "source": [
    "# Reconstrucción de parte de una imagen en base a otra\n",
    "\n",
    "En este cuaderno, vamos a entrenar un modelo de regresión lineal para que reconstruya la mitad de abajo de una imagen, utilizando como entrada la mitad de arriba. Como las imágenes son de 8x8, o sea 64 píxeles, la entrada serán entonces los 32 píxeles de arriba de la imagen, y la salida los 32 de abajo.\n",
    "\n",
    "Vamos a comparar dos métodos de optimización. El primero es el clásico método analítico basado en [cuadrados mínimos](https://en.wikipedia.org/wiki/Linear_least_squares) que se utiliza muy comunmente en estadística y utilizando la implementación de la librería [`sklearn`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). El otro es el descenso de gradiente estocástico. \n",
    "\n",
    "En este caso, veremos que el descenso de gradiente es superior al método analítico, dada la gran cantidad de variables de entrada y salida que requiere el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3TkzXRjR-ojn"
   },
   "outputs": [],
   "source": [
    "#paquetes\n",
    "%matplotlib notebook\n",
    "\n",
    "!pip install -q rnutil\n",
    "import rnutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.patches as patches\n",
    "from collections import namedtuple\n",
    "from matplotlib import cm\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oB_Ui6xo-ojo"
   },
   "outputs": [],
   "source": [
    "#Carga del dataset\n",
    "\n",
    "digits = load_digits()\n",
    "data=digits.images.reshape(-1,64)\n",
    "images=digits.images\n",
    "n,d=data.shape # n= cant ejemplos, d=tamaño de la imagen\n",
    "dx=32 # pixeles de la parte de arriba\n",
    "dy=d-dx # pixeles de la parte de abajo\n",
    "# x tiene la parte de arriba de la imagen\n",
    "x=data[:,0:dx]\n",
    "# y tiene la parte de abajo de la imagen\n",
    "y=data[:,dx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5NvlE-4H-ojo"
   },
   "outputs": [],
   "source": [
    "# Visualizamos ejemplos del dataset\n",
    "\n",
    "def plot_sample(x,y,sample_index,title=\"Original\"):\n",
    "    upper=x[sample_index,:].reshape((4,8))\n",
    "    lower=y[sample_index,:].reshape((4,8))\n",
    "    complete=np.vstack([upper,lower])\n",
    "    \n",
    "    fig,(a1,a2,a3)=plt.subplots(1,3,dpi=50)\n",
    "    plt.suptitle(title)\n",
    "    #Visualizar una muestra\n",
    "    a1.matshow(complete, cmap=cm.gray, vmin=0, vmax=16) \n",
    "    a1.set_title(\"Imagen entera\")\n",
    "    a1.axis(\"off\")\n",
    "\n",
    "    a2.imshow(upper, cmap=cm.gray, vmin=0, vmax=16)\n",
    "    a2.set_title(\"Mitad superior\")\n",
    "    a2.axis(\"off\")\n",
    "\n",
    "    a3.imshow(lower, cmap=cm.gray, vmin=0, vmax=16)\n",
    "    a3.set_title(\"Mitad inferior\")\n",
    "    a3.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "## CAMBIAR INDICE DE IMAGEN A VISUALIZAR\n",
    "sample_index=20\n",
    "plot_sample(x,y,sample_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7wscadw-ojp"
   },
   "source": [
    "# Optimización de los parámetros mediante cuadrádos mínimos (método analítico)\n",
    "\n",
    "Utilizando la librería `sklearn`, vamos a optimizar `w` y `b` utilizando un método analítico clásico. Este método no funciona bien para este problema por la gran cantidad de dimensiones del mismo y tiene un error sustancialmente peor que el modelo entrenado con descenso de graidente que veremos más abajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "icnPCf7K-ojq"
   },
   "outputs": [],
   "source": [
    "def analytic_model(x,y):\n",
    "    from sklearn import  linear_model\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x,y)\n",
    "    optimal_w=regr.coef_\n",
    "    optimal_b=regr.intercept_\n",
    "    y_pred_analytic=x.dot(optimal_w)+optimal_b\n",
    "    optimal_error=((y_pred_analytic-y)**2).mean()\n",
    "    \n",
    "    return optimal_w,optimal_b,optimal_error,y_pred_analytic\n",
    "\n",
    "# parámetros y error del modelo analítico\n",
    "analytic_w,analytic_b,analytic_error,y_pred_analytic = analytic_model(x,y)\n",
    "print(f\"Modelo analítico entrenado, error={analytic_error}\")\n",
    "\n",
    "sample_index=200\n",
    "plot_sample(x,y,sample_index)\n",
    "plot_sample(x,y_pred_analytic,sample_index,title=\"Reconstruida por modelo analítico\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cndd6mmX-ojq"
   },
   "source": [
    "# Entrenamiento de un modelo Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZndc06i-ojr"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "n,d_in=x.shape\n",
    "n,d_out=y.shape\n",
    "\n",
    "# Creación del modelo inicial\n",
    "print(\"Inicialización aleatoria del modelo; vuelve a correr esta celda para obtener otros resultados\")\n",
    "# Creo un modelo lineal\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(d_out,input_shape=(d_in,), activation=None)])\n",
    "\n",
    "sgd = keras.optimizers.SGD(learning_rate=0.001)\n",
    "model.compile(\n",
    "  optimizer=sgd,\n",
    "  loss=\"mse\",\n",
    "  metrics=[], # metricas para ir calculando en cada iteracion o batch (ninguna ahora)\n",
    ")\n",
    "print(f\"Entrenando modelo con descenso de gradiente...\")\n",
    "history=model.fit(x,y,batch_size=32,epochs=50,verbose=False)\n",
    "\n",
    "rnutil.plot_loss(history.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVmQ8Qeg-ojr"
   },
   "source": [
    "# Visualización de la reconstrucción del modelo entrenado con descenso de gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0o5Op6Jx-ojs"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x)\n",
    "\n",
    "sample_index=200\n",
    "plot_sample(x,y,sample_index)\n",
    "plot_sample(x,y_pred,sample_index,title=\"Reconstruida por modelo de Descenso de gradiente\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regresion Lineal Multiple - Keras - Imágenes.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
