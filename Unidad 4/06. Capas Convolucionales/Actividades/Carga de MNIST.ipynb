{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dfa04cd",
   "metadata": {},
   "source": [
    "# Carga de datos y verificación de tamaños"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c08c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"Formato de los datos de entrada (train,test)\")\n",
    "print(x_train.shape,x_test.shape)\n",
    "print(\"Formato de los datos de salida (train,test)\")\n",
    "print(y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52df0255",
   "metadata": {},
   "source": [
    "# Visualización de los ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c58a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "image_index=0\n",
    "print(f\"Visualización de la imagen N {image_index} (cambiar para ver otras)\")\n",
    "# plt.imshow muestra la imagen\n",
    "# cmap gray pone el mapa de color en escala de grises\n",
    "plt.imshow(x_train[0, :,:],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440b036d",
   "metadata": {},
   "source": [
    "# Formato de los datos\n",
    "\n",
    "El formato de los datos de imagen (entrada X) suele denominarse NHWC, indicando que un conjunto de imágenes se codifica con un tensor de 4 dimensiones, donde la primera es la dimensión de los datos/ejemplos (N ejemplos) y la segunda y tercera son las dimensiones espaciales (H y W, por Height y Width (alto y ancho)). La última, C, es la dimensión de canales. Para una imagen RGB, C=3, es decir, tiene 3 canales. Para una imagen de escala de grises, C=1, ya que tiene un solo canal.\n",
    "\n",
    "El dataset viene con el formato *NHW*, ya que al contener imágenes en escala de grises las mismas, hay un solo canal y en este caso se eligió obviarlo.\n",
    "\n",
    "Vamos a realizar algunas operaciones con `x_train` para explorar este formato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ce856",
   "metadata": {},
   "outputs": [],
   "source": [
    "n,h,w = x_train.shape\n",
    "print(f\"El conjunto de datos tiene {n} imágenes o ejemplos\")\n",
    "print(f\"Cada ejemplo es una imagen de tamaño {h}x{w}\")\n",
    "\n",
    "# Seleccionar los ejemplos 3 a 10\n",
    "seleccionados1 = x_train[3:10,:,:]\n",
    "print(\"Ejemplos del 3 al 10\")\n",
    "print(seleccionados1.shape)\n",
    "\n",
    "# Seleccionar la fila 3 de todas las imágenes\n",
    "seleccionados2 = x_train[:,3,:]\n",
    "print(\"Fila 3 de todas las imágenes\")\n",
    "print(seleccionados2.shape)\n",
    "\n",
    "# Calcular la suma de todos los pixeles\n",
    "suma = x_train.sum()\n",
    "\n",
    "# mostrar la mitad de arriba de la imágen 6\n",
    "plt.imshow(x_train[6,0:14,:],cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975523ec",
   "metadata": {},
   "source": [
    "# Conversion a un formato ND (ejemplos x pixeles) para procesar con capas Dense\n",
    "\n",
    "Para procesar los datos con capas dense, las mismas esperan que los datos se codifiquen como un vector. Por ende, vamos a reorganizar las entradas para que se codifiquen como un vector que consiste en una tira de todos los pixeles de la imagen. \n",
    "En este caso, como cada imagen es de tamaño $28x28$ en formato matricial, como vector tendra tamaño $28x28 = 784$\n",
    "\n",
    "De esta forma, los datos podrán ser usados con un framework y una red, en donde la primera capa es una capa Dense.\n",
    "\n",
    "Para eso, podemos utilizar la función `reshape`. \n",
    "\n",
    "NOTA: Alternativamente, se pueden dejar los datos como están, y utilizar la capa `Flatten` de Keras para hacer esta misma conversión de forma automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "x_train_dense = x_train.reshape([-1,28*28]) # equivalentemente [n,h*w]\n",
    "x_test_dense =  x_test.reshape([-1,28*28])\n",
    "\n",
    "print(\"Formato de los datos de entrada para capas densas (train,test)\")\n",
    "print(x_train_dense.shape,x_test_dense.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb4877",
   "metadata": {},
   "source": [
    "# Conversion a un formato NHWC (filas, columnas y canales) para procesar con capas Convolucionales\n",
    "\n",
    "\n",
    "En el caso de las capas convolucionales, necesitamos que las imagenes tengan la estructura 2D espacial, pero además que respeten en el formato NHWC que incluye las columnas. Vamos a agregar esta dimensión extra nuevamente con `reshape`, para que los datos puedan ser usados con un framework y una red, en donde la primera capa es una capa convolucional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1ddf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "x_train_conv = x_train.reshape([-1,28,28,1]) # equivalentemente [n,h,w,1]\n",
    "x_test_conv = x_train.reshape([-1,28,28,1])\n",
    "\n",
    "print(\"Formato de los datos de entrada para capas convolucionales (train,test)\")\n",
    "print(x_train_conv.shape,x_test_conv.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
